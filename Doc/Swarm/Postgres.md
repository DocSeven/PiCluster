# Postgres Cluster on Docker Swarm

## Replication

To run a postgres streaming replication cluster on Docker Swarm, you first need to have a "Postgres" image. However, the official image does not support replication out of the box and commercial solutions such as Patroni/Citus couldn't be compiled on the Raspberry Pi. The only RPi-compatible image we found was a private open-source project from: https://github.com/sameersbn/docker-postgresql. You can either build it yourself or use our build: https://hub.docker.com/repository/docker/pgigeruzh/postgres

```bash
# Run Master on cluster1raspberry0
docker service create --name postgresmaster --network spark --publish 54320:5432 --constraint=node.hostname==cluster1raspberry0 --env PG_PASSWORD=password --env REPLICATION_USER=postgres --env REPLICATION_PASS=password pgigeruzh/postgres

# Run Slave1 on cluster1raspberry1
docker service create --name postgresslave1 --network spark --publish 54321:5432 --constraint=node.hostname==cluster1raspberry1 --env REPLICATION_MODE=slave --env REPLICATION_SSLMODE=prefer --env REPLICATION_HOST=postgresmaster --env REPLICATION_PORT=5432 --env REPLICATION_USER=postgres --env REPLICATION_PASS=password pgigeruzh/postgres

# Run Slave2 on cluster1raspberry2
docker service create --name postgresslave2 --network spark --publish 54322:5432 --constraint=node.hostname==cluster1raspberry2 --env REPLICATION_MODE=slave --env REPLICATION_SSLMODE=prefer --env REPLICATION_HOST=postgresmaster --env REPLICATION_PORT=5432 --env REPLICATION_USER=postgres --env REPLICATION_PASS=password pgigeruzh/postgres

# Run Slave3 on cluster1raspberry3
docker service create --name postgresslave3 --network spark --publish 54323:5432 --constraint=node.hostname==cluster1raspberry3 --env REPLICATION_MODE=slave --env REPLICATION_SSLMODE=prefer --env REPLICATION_HOST=postgresmaster --env REPLICATION_PORT=5432 --env REPLICATION_USER=postgres --env REPLICATION_PASS=password pgigeruzh/postgres

# Run Pgpool II
docker service create --name pgpool --network spark --publish 5432:5432 --env USER=postgres --env PASSWORD=password --env HOSTS=postgresmaster:5432:postgresslave1:5432:postgresslave2:5432:postgresslave3:5432 pgigeruzh/pgpool
```

It has to be noted that the databases have to be constraint (--constraint=node.hostname) to a certain node because Docker Swarm doesn't move/share volumes accross nodes. For persistent storage, mount the local filesystem to /var/lib/postgresql.

To take advantage of the streaming replication, a load balancer can be added. [Pgpool](https://www.pgpool.net/) is a load balancer for Postgres and support automatic failovers in case a node dies. The documentation can be found here: https://github.com/pgigeruzh/pgpool



## Sharding

For sharding, it is recommended to use the latest Postgres image because the sharding features are under active development.

```bash
# Run Master on cluster1raspberry0
docker service create --name postgresmaster --network spark --publish 54320:5432 --constraint=node.hostname==cluster1raspberry0 --env POSTGRES_PASSWORD=password postgres

# Run Slave1 on cluster1raspberry1
docker service create --name postgresslave1 --network spark --publish 54321:5432 --constraint=node.hostname==cluster1raspberry1 --env POSTGRES_PASSWORD=password postgres

# Run Slave2 on cluster1raspberry2
docker service create --name postgresslave2 --network spark --publish 54322:5432 --constraint=node.hostname==cluster1raspberry2 --env POSTGRES_PASSWORD=password postgres

# Run Slave3 on cluster1raspberry3
docker service create --name postgresslave3 --network spark --publish 54323:5432 --constraint=node.hostname==cluster1raspberry3 --env POSTGRES_PASSWORD=password postgres
```

The following examples are based on data generated by pgbench (see [Benchmark](https://github.com/pgigeruzh/PiCluster/tree/master/Benchmarks#postgres)). Pgbench creates and fills four tables namely pgbench_branches, pgbench_tellers, pgbench_accounts, and pgbench_history. It is assumed that all tables are filled and initialized on the master. The largest table is pgbench_accounts and will be sharded accross all nodes. To do so, the pgbench_accounts table has to be created on all slaves.

```sql
-- Run on Slave1
CREATE DATABASE bench_test;
CREATE TABLE pgbench_accounts_partition1
(
    aid integer NOT NULL PRIMARY KEY,
    bid integer,
    abalance integer,
    filler character(84) COLLATE pg_catalog."default"
);

-- Run on Slave2
CREATE DATABASE bench_test;
CREATE TABLE pgbench_accounts_partition2
(
    aid integer NOT NULL PRIMARY KEY,
    bid integer,
    abalance integer,
    filler character(84) COLLATE pg_catalog."default"
);

-- Run on Slave3
CREATE DATABASE bench_test;
CREATE TABLE pgbench_accounts_partition3
(
    aid integer NOT NULL PRIMARY KEY,
    bid integer,
    abalance integer,
    filler character(84) COLLATE pg_catalog."default"
);
```

Afterwards, the already filled table on the master has to be replaced by a partitioned table.

```sql
-- Run on Master

-- Rename pgbench_accounts table
ALTER TABLE pgbench_accounts RENAME TO pgbench_accounts_old;
-- Create new pgbench_accounts table with partitioning
CREATE TABLE pgbench_accounts
(
    aid integer NOT NULL,
    bid integer,
    abalance integer,
    filler character(84) COLLATE pg_catalog."default"
) PARTITION BY RANGE (aid);
```

Last but not least, all slaves have to be connected using fdw (foreign data wrapper). This way, the newly created tables on the slaves are seen as "local" tables by the master. Then, the tables can be partitioned (in this case by range) and refilled.

```sql
-- Run on Master

-- Connect to all Slaves from Master
CREATE EXTENSION postgres_fdw;
CREATE SERVER postgresslave1 FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host 'postgresslave1', dbname 'bench_test');
CREATE USER MAPPING for postgres SERVER postgresslave1 OPTIONS (user 'postgres', password 'password');
CREATE SERVER postgresslave2 FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host 'postgresslave2', dbname 'bench_test');
CREATE USER MAPPING for postgres SERVER postgresslave2 OPTIONS (user 'postgres', password 'password');
CREATE SERVER postgresslave3 FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host 'postgresslave3', dbname 'bench_test');
CREATE USER MAPPING for postgres SERVER postgresslave3 OPTIONS (user 'postgres', password 'password');

-- Connect the tables from the slaves as partitions
CREATE TABLE pgbench_accounts_partition0 PARTITION OF pgbench_accounts FOR VALUES FROM (0) TO (250000);
CREATE FOREIGN TABLE pgbench_accounts_partition1 PARTITION OF pgbench_accounts FOR VALUES FROM (250000) TO (500000) SERVER postgresslave1;
CREATE FOREIGN TABLE pgbench_accounts_partition2 PARTITION OF pgbench_accounts FOR VALUES FROM (500000) TO (750000) SERVER postgresslave2;
CREATE FOREIGN TABLE pgbench_accounts_partition3 PARTITION OF pgbench_accounts FOR VALUES FROM (750000) TO (1000001) SERVER postgresslave3;

-- Insert data from old database
INSERT INTO pgbench_accounts SELECT * FROM pgbench_accounts_old;
```

### Local Partitioning

Partitions don't have to be sharded accross nodes. For local usage, there is no need to use the fdw (foreign data wrapper) which makes things easier.

```sql
-- Rename pgbench_accounts table
ALTER TABLE pgbench_accounts RENAME TO pgbench_accounts_old;

-- Create new pgbench_accounts table with partitioning
CREATE TABLE pgbench_accounts
(
    aid integer NOT NULL PRIMARY KEY,
    bid integer,
    abalance integer,
    filler character(84) COLLATE pg_catalog."default"
) PARTITION BY RANGE (aid);
-- Add partitions
CREATE TABLE pgbench_accounts_p1 PARTITION OF pgbench_accounts FOR VALUES FROM (0) TO (250000);
CREATE TABLE pgbench_accounts_p2 PARTITION OF pgbench_accounts FOR VALUES FROM (250000) TO (500000);
CREATE TABLE pgbench_accounts_p3 PARTITION OF pgbench_accounts FOR VALUES FROM (500000) TO (750000);
CREATE TABLE pgbench_accounts_p4 PARTITION OF pgbench_accounts FOR VALUES FROM (750000) TO (1000001);

-- Insert data from old table
INSERT INTO pgbench_accounts SELECT * FROM pgbench_accounts_old;
```

