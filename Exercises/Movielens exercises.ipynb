{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Analytics with MovieLens Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we will use the [MovieLens 20M Dataset](https://grouplens.org/datasets/movielens/20m/) on movie ratings to answer several tasks by using `pySpark`. The exercises are structured as a guideline to get familiar with the Spark and pyspark syntax. Have also a look on the [official pySpark documentation](https://spark.apache.org/docs/latest/api/python/pyspark.html). \n",
    "\n",
    "**Introduction to Movielens dataset**\n",
    "\n",
    "The Introduction exercises have the following goals:\n",
    "- Reading and understanding the schema of our movielens dataset\n",
    "- Calculating some summary statistics of our dataset\n",
    "- Learn how to perform joins and aggregations using Spark\n",
    "- Sample exercise 1: Which movies are the most popular ones?\n",
    "- Sample exercise 2: Creating RDD's\n",
    "\n",
    "\n",
    "**Exercises**\n",
    "- Basic exercise 1: Which movies have the highest number of ratings?\n",
    "- Basic exercise 2: Something with RDD's\n",
    "- Advanced exercise 1: Which movies are a matter of taste?\n",
    "\n",
    "**Remark**: Pyspark needs to be installed to work with the Jupyter Notebook (e.g. Anaconda3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Sparksession\n",
    "\n",
    "Execute the following cell to initialize a Sparksession:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('MovieLens').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our movielens dataset contains 20 million ratings and 465'000 tag applications applied to 27'000 movies by 138'000 users. It also includs tag genome data with 12 million relevance scores across 1100 tags.\n",
    "\n",
    "The whole dataset contains six CSV files:\n",
    "- genome-scores.csv\n",
    "- genome-tags.csv\n",
    "- links.csv\n",
    "- movies.csv\n",
    "- ratings.csv\n",
    "- tags.csv\n",
    "\n",
    "First, we will have a look on the **`movies`** and **`ratings`** dataframes.\n",
    "\n",
    "To read a CSV file in our \"ml-20m\" folder, we access the `DataFrameReader` class through `read` and call the `csv()` method on it. We also specify `option(\"header\", \"true\")` since the first row of the file contains our column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      2|   3.5|1112486027|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|     32|   3.5|1112484819|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "|     1|     50|   3.5|1112484580|\n",
      "|     1|    112|   3.5|1094785740|\n",
      "|     1|    151|   4.0|1094785734|\n",
      "|     1|    223|   4.0|1112485573|\n",
      "|     1|    253|   4.0|1112484940|\n",
      "|     1|    260|   4.0|1112484826|\n",
      "|     1|    293|   4.0|1112484703|\n",
      "|     1|    296|   4.0|1112484767|\n",
      "|     1|    318|   4.0|1112484798|\n",
      "|     1|    337|   3.5|1094785709|\n",
      "|     1|    367|   3.5|1112485980|\n",
      "|     1|    541|   4.0|1112484603|\n",
      "|     1|    589|   3.5|1112485557|\n",
      "|     1|    593|   3.5|1112484661|\n",
      "|     1|    653|   3.0|1094785691|\n",
      "|     1|    919|   3.5|1094785621|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.option(\"header\", \"true\").csv(\"ml-20m/ratings.csv\")\n",
    "ratings.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tuple of the `ratings` DataFrame represents one rating (`rating`) for one movie (`movieId`) by one user (`userId`). The ratings ranges from 0.5 stars (worst) up to 5.0 stars (best). \n",
    "\n",
    "We can also have look on the Schema of our dataset (column names and types) by using the `printSchema()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the `movies.csv` file. What kind of data is available and how does the schema look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = spark.read.option(\"header\", \"true\").csv(\"ml-20m/movies.csv\")\n",
    "movies.show(20)\n",
    "\n",
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro exercise 1: Which movies are the most popular ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the most popular movies, we are looking for the movies with the highest number of ratings. In this task, we assume the number of ratings as a representative for the number of views. To do this, we will perform the following *transformations* on the `ratings` DataFrame: \n",
    "- group by `movieId`\n",
    "- count the number of users (`userId`) associated with each movie \n",
    "- rename this column to `num_ratings`\n",
    "- sort by `num_ratings` in descending order \n",
    "\n",
    "We do these transformations in `pySpark` and store the DataFrame as `most_popular`. Have also a look on the [official pySpark documentation](https://spark.apache.org/docs/latest/api/python/pyspark.html).\n",
    "\n",
    "**HINT**:\n",
    "- Use `agg(count())` to perform an aggregate calculation on grouped data. \n",
    "- Don't forget that transformations are [lazy](https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-operations) in spark. We need to call an action (e.g. `show()`, `take()`) explicitly to see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|movieId|num_ratings|\n",
      "+-------+-----------+\n",
      "|    296|      67310|\n",
      "|    356|      66172|\n",
      "|    318|      63366|\n",
      "|    593|      63299|\n",
      "|    480|      59715|\n",
      "|    260|      54502|\n",
      "|    110|      53769|\n",
      "|    589|      52244|\n",
      "|   2571|      51334|\n",
      "|    527|      50054|\n",
      "|      1|      49695|\n",
      "|    457|      49581|\n",
      "|    150|      47777|\n",
      "|    780|      47048|\n",
      "|     50|      47006|\n",
      "|   1210|      46839|\n",
      "|    592|      46054|\n",
      "|   1196|      45313|\n",
      "|   2858|      44987|\n",
      "|     32|      44980|\n",
      "+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "most_popular = ratings.groupBy(\"movieId\").agg(count(\"userId\")).withColumnRenamed(\"count(userId)\", \"num_ratings\").sort(desc(\"num_ratings\"))\n",
    "\n",
    "most_popular.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the resulting table only contains `movieId` and `num_ratings`. The title of the movie is stored in the `movies` DataFrame. So, we need an inner join of our `most_popular` DataFrame with the `movies` DataFrame on `movieId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------+-----------------------------------------------------+-------------------------------------------+\n",
      "|movieId|num_ratings|movieId|title                                                |genres                                     |\n",
      "+-------+-----------+-------+-----------------------------------------------------+-------------------------------------------+\n",
      "|296    |67310      |296    |Pulp Fiction (1994)                                  |Comedy|Crime|Drama|Thriller                |\n",
      "|356    |66172      |356    |Forrest Gump (1994)                                  |Comedy|Drama|Romance|War                   |\n",
      "|318    |63366      |318    |Shawshank Redemption, The (1994)                     |Crime|Drama                                |\n",
      "|593    |63299      |593    |Silence of the Lambs, The (1991)                     |Crime|Horror|Thriller                      |\n",
      "|480    |59715      |480    |Jurassic Park (1993)                                 |Action|Adventure|Sci-Fi|Thriller           |\n",
      "|260    |54502      |260    |Star Wars: Episode IV - A New Hope (1977)            |Action|Adventure|Sci-Fi                    |\n",
      "|110    |53769      |110    |Braveheart (1995)                                    |Action|Drama|War                           |\n",
      "|589    |52244      |589    |Terminator 2: Judgment Day (1991)                    |Action|Sci-Fi                              |\n",
      "|2571   |51334      |2571   |Matrix, The (1999)                                   |Action|Sci-Fi|Thriller                     |\n",
      "|527    |50054      |527    |Schindler's List (1993)                              |Drama|War                                  |\n",
      "|1      |49695      |1      |Toy Story (1995)                                     |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|457    |49581      |457    |Fugitive, The (1993)                                 |Thriller                                   |\n",
      "|150    |47777      |150    |Apollo 13 (1995)                                     |Adventure|Drama|IMAX                       |\n",
      "|780    |47048      |780    |Independence Day (a.k.a. ID4) (1996)                 |Action|Adventure|Sci-Fi|Thriller           |\n",
      "|50     |47006      |50     |Usual Suspects, The (1995)                           |Crime|Mystery|Thriller                     |\n",
      "|1210   |46839      |1210   |Star Wars: Episode VI - Return of the Jedi (1983)    |Action|Adventure|Sci-Fi                    |\n",
      "|592    |46054      |592    |Batman (1989)                                        |Action|Crime|Thriller                      |\n",
      "|1196   |45313      |1196   |Star Wars: Episode V - The Empire Strikes Back (1980)|Action|Adventure|Sci-Fi                    |\n",
      "|2858   |44987      |2858   |American Beauty (1999)                               |Comedy|Drama                               |\n",
      "|32     |44980      |32     |Twelve Monkeys (a.k.a. 12 Monkeys) (1995)            |Mystery|Sci-Fi|Thriller                    |\n",
      "+-------+-----------+-------+-----------------------------------------------------+-------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_popular_movies = most_popular.join(movies, most_popular.movieId == movies.movieId)\n",
    "most_popular_movies.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of the most popular (or most rated) movies of our movielens dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro exercise 2: Understanding RDD's (Resilient Distributed Datasets)\n",
    "\n",
    "--> still ongoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['userId', 'movieId', 'rating', 'timestamp'],\n",
       " ['1', '2', '3.5', '1112486027'],\n",
       " ['1', '29', '3.5', '1112484676'],\n",
       " ['1', '32', '3.5', '1112484819'],\n",
       " ['1', '47', '3.5', '1112484727']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into RDD\n",
    "data = sc.textFile(\"ml-20m/ratings.csv\")\n",
    "\n",
    "# Split the RDD \n",
    "ratings = data.map(lambda l: l.split(','))\n",
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['timestamp', 'rating', 'movieId', 'userId'],\n",
       " ['1112486027', '3.5', '2', '1'],\n",
       " ['1112484676', '3.5', '29', '1'],\n",
       " ['1112484819', '3.5', '32', '1'],\n",
       " ['1112484727', '3.5', '47', '1']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map\n",
    "Reversed = ratings.map(lambda rating: rating[::-1])\n",
    "Reversed.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId',\n",
       " 'movieId',\n",
       " 'rating',\n",
       " 'timestamp',\n",
       " '1',\n",
       " '2',\n",
       " '3.5',\n",
       " '1112486027',\n",
       " '1',\n",
       " '29']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatMap\n",
    "characters = ratings.flatMap(lambda rating: list(rating))\n",
    "characters.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic exercise 1: Which movies have the highest ratings (in average)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see which movies are rated to be the best. We will use the `ratings` DataFrame and: \n",
    "\n",
    "- Group by `movieId` \n",
    "- Calculate the average rating for each movie and rename this column to `avg_rating`\n",
    "- Sort by `avg_rating` in descending order \n",
    "- Join the resulting DataFrame with the `movies` DataFrame to get the movienames.\n",
    "\n",
    "**NOTE** Be sure that you read the movies file in the first part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+--------------------+--------------------+\n",
      "|movieId|avg_rating|movieId|               title|              genres|\n",
      "+-------+----------+-------+--------------------+--------------------+\n",
      "|  95517|       5.0|  95517|Barchester Chroni...|               Drama|\n",
      "| 109715|       5.0| 109715|Inquire Within (2...|              Comedy|\n",
      "| 111548|       5.0| 111548|Welcome to Austra...|         Documentary|\n",
      "| 129905|       5.0| 129905|The Floating Cast...|        Comedy|Drama|\n",
      "|  98761|       5.0|  98761|Shaolin Temple 2:...|       Action|Comedy|\n",
      "|  27914|       5.0|  27914|Hijacking Catastr...|         Documentary|\n",
      "| 129305|       5.0| 129305|Pretty Things (2001)|               Drama|\n",
      "| 106113|       5.0| 106113|Such Hawks Such H...|         Documentary|\n",
      "|  94431|       5.0|  94431|Ella Lola, a la T...|  (no genres listed)|\n",
      "|  93707|       5.0|  93707|Prom Queen: The M...|        Comedy|Drama|\n",
      "| 127256|       5.0| 127256|  The Old Gun (1975)|  Drama|Thriller|War|\n",
      "|  95979|       5.0|  95979|      Oranges (2004)|               Drama|\n",
      "| 113790|       5.0| 113790|Peace, Propaganda...|         Documentary|\n",
      "| 106082|       5.0| 106082|Shock and Awe: Th...|         Documentary|\n",
      "| 117606|       5.0| 117606|      Divorce (1945)|               Drama|\n",
      "| 113860|       5.0| 113860|Codes of Gender, ...|         Documentary|\n",
      "| 105191|       5.0| 105191| Rocaterrania (2009)| Documentary|Fantasy|\n",
      "| 109253|       5.0| 109253|Argentina latente...|         Documentary|\n",
      "| 108527|       5.0| 108527|  Catastroika (2012)|         Documentary|\n",
      "| 113947|       5.0| 113947|Lady of Chance, A...|Comedy|Drama|Romance|\n",
      "+-------+----------+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_rated = ratings.groupBy(\"movieId\").agg(avg(col(\"rating\"))).withColumnRenamed(\"avg(rating)\", \"avg_rating\").sort(desc(\"avg_rating\"))\n",
    "\n",
    "top_rated_movies = top_rated.join(movies, top_rated.movieId == movies.movieId)\n",
    "\n",
    "top_rated_movies.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting Dataframe is maybe not meaningful. We should also consider the number of ratings by doing an aggregation `agg()` call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----------+-------+--------------------+-------------------+\n",
      "|movieId|num_ratings|avg_rating|movieId|               title|             genres|\n",
      "+-------+-----------+----------+-------+--------------------+-------------------+\n",
      "| 108527|          2|       5.0| 108527|  Catastroika (2012)|        Documentary|\n",
      "| 103871|          2|       5.0| 103871|Consuming Kids: T...|        Documentary|\n",
      "|  86055|          1|       5.0|  86055|Foster Brothers, ...|             Comedy|\n",
      "| 109253|          1|       5.0| 109253|Argentina latente...|        Documentary|\n",
      "| 117606|          1|       5.0| 117606|      Divorce (1945)|              Drama|\n",
      "| 129305|          1|       5.0| 129305|Pretty Things (2001)|              Drama|\n",
      "| 113860|          1|       5.0| 113860|Codes of Gender, ...|        Documentary|\n",
      "| 106082|          1|       5.0| 106082|Shock and Awe: Th...|        Documentary|\n",
      "| 113790|          1|       5.0| 113790|Peace, Propaganda...|        Documentary|\n",
      "|  98761|          1|       5.0|  98761|Shaolin Temple 2:...|      Action|Comedy|\n",
      "| 127256|          1|       5.0| 127256|  The Old Gun (1975)| Drama|Thriller|War|\n",
      "|  94431|          1|       5.0|  94431|Ella Lola, a la T...| (no genres listed)|\n",
      "| 106113|          1|       5.0| 106113|Such Hawks Such H...|        Documentary|\n",
      "|  95979|          1|       5.0|  95979|      Oranges (2004)|              Drama|\n",
      "|  93707|          1|       5.0|  93707|Prom Queen: The M...|       Comedy|Drama|\n",
      "|  95517|          1|       5.0|  95517|Barchester Chroni...|              Drama|\n",
      "| 105191|          1|       5.0| 105191| Rocaterrania (2009)|Documentary|Fantasy|\n",
      "|  27914|          1|       5.0|  27914|Hijacking Catastr...|        Documentary|\n",
      "| 109715|          1|       5.0| 109715|Inquire Within (2...|             Comedy|\n",
      "| 129905|          1|       5.0| 129905|The Floating Cast...|       Comedy|Drama|\n",
      "+-------+-----------+----------+-------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_rated = ratings.groupBy(\"movieId\").agg(count(\"userId\"), avg(col(\"rating\"))).withColumnRenamed(\"count(userId)\", \"num_ratings\").withColumnRenamed(\"avg(rating)\", \"avg_rating\")\n",
    "\n",
    "top_rated_movies = top_rated.join(movies, top_rated.movieId == movies.movieId).sort(desc(\"avg_rating\"), desc(\"num_ratings\"))\n",
    "\n",
    "top_rated_movies.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the movies with `avg_rating` of exactly 5.0 have 2 or less `num_ratings` . We must investigate the distribution of `num_ratings` to only consider movies that have a minimum number of ratings. Let's calculate some summary statistics within Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+\n",
      "| avg(num_ratings)|min(num_ratings)|max(num_ratings)|\n",
      "+-----------------+----------------+----------------+\n",
      "|747.8411232425965|               1|           67310|\n",
      "+-----------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate average, minimum, and maximum of num_ratings\n",
    "top_rated_movies.select([mean('num_ratings'), min('num_ratings'), max('num_ratings')]).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------+-------+---------------------------------------------------------------------------+-----------------------------------------+\n",
      "|movieId|num_ratings|avg_rating        |movieId|title                                                                      |genres                                   |\n",
      "+-------+-----------+------------------+-------+---------------------------------------------------------------------------+-----------------------------------------+\n",
      "|318    |63366      |4.446990499637029 |318    |Shawshank Redemption, The (1994)                                           |Crime|Drama                              |\n",
      "|858    |41355      |4.364732196832306 |858    |Godfather, The (1972)                                                      |Crime|Drama                              |\n",
      "|50     |47006      |4.334372207803259 |50     |Usual Suspects, The (1995)                                                 |Crime|Mystery|Thriller                   |\n",
      "|527    |50054      |4.310175010988133 |527    |Schindler's List (1993)                                                    |Drama|War                                |\n",
      "|1221   |27398      |4.275640557704942 |1221   |Godfather: Part II, The (1974)                                             |Crime|Drama                              |\n",
      "|2019   |11611      |4.2741796572216   |2019   |Seven Samurai (Shichinin no samurai) (1954)                                |Action|Adventure|Drama                   |\n",
      "|904    |17449      |4.271333600779414 |904    |Rear Window (1954)                                                         |Mystery|Thriller                         |\n",
      "|7502   |4305       |4.263182346109176 |7502   |Band of Brothers (2001)                                                    |Action|Drama|War                         |\n",
      "|912    |24349      |4.258326830670664 |912    |Casablanca (1942)                                                          |Drama|Romance                            |\n",
      "|922    |6525       |4.256934865900383 |922    |Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)                              |Drama|Film-Noir|Romance                  |\n",
      "|1193   |29932      |4.24807897901911  |1193   |One Flew Over the Cuckoo's Nest (1975)                                     |Drama                                    |\n",
      "|750    |23220      |4.247286821705426 |750    |Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)|Comedy|War                               |\n",
      "|1212   |6565       |4.246001523229246 |1212   |Third Man, The (1949)                                                      |Film-Noir|Mystery|Thriller               |\n",
      "|6016   |12937      |4.235410064157069 |6016   |City of God (Cidade de Deus) (2002)                                        |Action|Adventure|Crime|Drama|Thriller    |\n",
      "|44555  |5720       |4.2347902097902095|44555  |Lives of Others, The (Das leben der Anderen) (2006)                        |Drama|Romance|Thriller                   |\n",
      "|908    |15627      |4.233538107122288 |908    |North by Northwest (1959)                                                  |Action|Adventure|Mystery|Romance|Thriller|\n",
      "|1178   |3568       |4.2326233183856505|1178   |Paths of Glory (1957)                                                      |Drama|War                                |\n",
      "|2959   |40106      |4.227123123722136 |2959   |Fight Club (1999)                                                          |Action|Crime|Drama|Thriller              |\n",
      "|3435   |4909       |4.224281931146873 |3435   |Double Indemnity (1944)                                                    |Crime|Drama|Film-Noir                    |\n",
      "|1203   |12934      |4.224137931034483 |1203   |12 Angry Men (1957)                                                        |Drama                                    |\n",
      "+-------+-----------+------------------+-------+---------------------------------------------------------------------------+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_rated_movies.where(\"num_ratings > 800\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing SparkSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: top_rated_movies; line 1 pos 14'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\spark\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o25.sql.\n: org.apache.spark.sql.AnalysisException: Table or view not found: top_rated_movies; line 1 pos 14\r\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:47)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:731)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:683)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:713)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:706)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:706)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:652)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\r\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\r\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:106)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\r\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: Table or view 'top_rated_movies' not found in database 'default';\r\n\tat org.apache.spark.sql.hive.client.HiveClient$$anonfun$getTable$1.apply(HiveClient.scala:81)\r\n\tat org.apache.spark.sql.hive.client.HiveClient$$anonfun$getTable$1.apply(HiveClient.scala:81)\r\n\tat scala.Option.getOrElse(Option.scala:121)\r\n\tat org.apache.spark.sql.hive.client.HiveClient$class.getTable(HiveClient.scala:81)\r\n\tat org.apache.spark.sql.hive.client.HiveClientImpl.getTable(HiveClientImpl.scala:84)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.getRawTable(HiveExternalCatalog.scala:118)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$getTable$1.apply(HiveExternalCatalog.scala:700)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$getTable$1.apply(HiveExternalCatalog.scala:700)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)\r\n\tat org.apache.spark.sql.hive.HiveExternalCatalog.getTable(HiveExternalCatalog.scala:699)\r\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.getTable(ExternalCatalogWithListener.scala:138)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupRelation(SessionCatalog.scala:706)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:728)\r\n\t... 63 more\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-ee775ce4b690>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"select * from top_rated_movies where num_ratings > 800\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\spark\\spark\\python\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36msql\u001b[1;34m(self, sqlQuery)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'row1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'row2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'row3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \"\"\"\n\u001b[1;32m--> 767\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: 'Table or view not found: top_rated_movies; line 1 pos 14'"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from top_rated_movies where num_ratings > 800\").show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic exercise 2: Something with RDD's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced exercise 1: Which movies are a matter of taste?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, movies are a matter of taste. There are for sure some movies, which you would rate with a 5 whereas your friend rates the same movie with a 2. These are the movies that divide your opinon. Try to find out, which movies belong to this category.\n",
    "\n",
    "**HINT**\n",
    "\n",
    "- We need to consider the standard deviation of the movie ratings\n",
    "- Also, try to consider only movies that have some minimum number of ratings (e.g. 700) \n",
    "- Join with the movies table to get the movie names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------+------------------+\n",
      "|movieId|num_ratings|        avg_rating|        std_rating|\n",
      "+-------+-----------+------------------+------------------+\n",
      "|    296|      67310| 4.174231169217055|0.9760762295742448|\n",
      "|   1090|      15808| 3.919977226720648|0.8272067263021853|\n",
      "|   3959|       2869| 3.699372603694667|0.8607671626686736|\n",
      "|   2294|      10163| 3.303207714257601|0.9047000233824075|\n",
      "|   6731|       1173|3.5571184995737424| 0.918929235043451|\n",
      "|  48738|       4163| 3.895868364160461|0.6545425744035035|\n",
      "|   3210|       7968|3.6711219879518073|0.9119945444634687|\n",
      "|  88140|       2313|3.5536100302637266|0.8756738276071163|\n",
      "|    467|        741|3.3832658569500675|1.2721828955638057|\n",
      "|   2088|       3539| 2.562729584628426|1.0602369201260298|\n",
      "+-------+-----------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_stddev = ratings.groupBy(\"movieId\").agg(count(\"userId\").alias(\"num_ratings\"), \n",
    "avg(col(\"rating\")).alias(\"avg_rating\"),stddev(col(\"rating\")).alias(\"std_rating\")).where(\"num_ratings > 700\")\n",
    "\n",
    "ratings_stddev.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------+------------------+-------+---------------------------------------------+-------------------------------------+\n",
      "|movieId|num_ratings|avg_rating        |std_rating        |movieId|title                                        |genres                               |\n",
      "+-------+-----------+------------------+------------------+-------+---------------------------------------------+-------------------------------------+\n",
      "|1924   |2304       |2.6319444444444446|1.420171182322382 |1924   |Plan 9 from Outer Space (1959)               |Horror|Sci-Fi                        |\n",
      "|4255   |1550       |2.1351612903225807|1.3504497277537106|4255   |Freddy Got Fingered (2001)                   |Comedy                               |\n",
      "|78772  |884        |2.670814479638009 |1.3485057430514158|78772  |Twilight Saga: Eclipse, The (2010)           |Fantasy|Romance|Thriller|IMAX        |\n",
      "|72407  |1135       |2.565638766519824 |1.3367548401080391|72407  |Twilight Saga: New Moon, The (2009)          |Drama|Fantasy|Horror|Romance|Thriller|\n",
      "|7318   |3130       |3.185623003194888 |1.335427370705759 |7318   |Passion of the Christ, The (2004)            |Drama                                |\n",
      "|63992  |2156       |2.74652133580705  |1.3226079682187069|63992  |Twilight (2008)                              |Drama|Fantasy|Romance|Thriller       |\n",
      "|1105   |922        |2.3345986984815617|1.3217574182346987|1105   |Children of the Corn IV: The Gathering (1996)|Horror                               |\n",
      "|747    |1084       |2.3325645756457565|1.3141605603130373|747    |Stupids, The (1996)                          |Comedy                               |\n",
      "|8531   |1177       |2.3343245539507222|1.2991013665459508|8531   |White Chicks (2004)                          |Action|Comedy|Crime                  |\n",
      "|5047   |1305       |2.7203065134099615|1.2916116452609896|5047   |Kung Pow: Enter the Fist (2002)              |Action|Comedy                        |\n",
      "+-------+-----------+------------------+------------------+-------+---------------------------------------------+-------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matterofTaste_movies = ratings_stddev.join(movies, ratings_stddev.movieId == movies.movieId)\n",
    "\n",
    "matterofTaste_movies.sort(desc(\"std_rating\")).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any surprise, Twilight is a highly debated movie ;) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "238px",
    "width": "412px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
