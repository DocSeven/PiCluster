{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Analytics with MovieLens Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we will use the [MovieLens 20M Dataset](https://grouplens.org/datasets/movielens/20m/) on movie ratings to answer several tasks by using `pySpark`. The exercises are structured as a guideline to get familiar with the pyspark syntax. Have also a look on the [official pySpark documentation](https://spark.apache.org/docs/latest/api/python/pyspark.html). \n",
    "\n",
    "**Introduction to Movielens dataset**\n",
    "\n",
    "The Introduction exercises have the following goals:\n",
    "- Reading and understanding the schema of our movielens dataset\n",
    "- Calculating some summary statistics of our dataset\n",
    "- Learn how to perform joins and aggregations using Spark\n",
    "- Sample exercise 1: Which movies are the most popular ones?\n",
    "- Sample exercise 2: Creating RDD's\n",
    "\n",
    "\n",
    "**Exercises**\n",
    "- Basic exercise 1: Which movies have the highest number of ratings?\n",
    "- Basic exercise 2: Something with RDD's\n",
    "- Advanced exercise 1: Which movies are a matter of taste?\n",
    "\n",
    "**Remark**: Pyspark needs to be installed to work with the Jupyter Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Sparksession\n",
    "\n",
    "Execute the following cell to initialize a Sparksession:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('MovieLens').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our movielens dataset contains 20 million ratings and 465'000 tag applications applied to 27'000 movies by 138'000 users. It also includs tag genome data with 12 million relevance scores across 1100 tags.\n",
    "\n",
    "The whole dataset contains six CSV files:\n",
    "- genome-scores.csv\n",
    "- genome-tags.csv\n",
    "- links.csv\n",
    "- movies.csv\n",
    "- ratings.csv\n",
    "- tags.csv\n",
    "\n",
    "First, we will have a look on the **`movies`** and **`ratings`** dataframes.\n",
    "\n",
    "To read a CSV file in our \"ml-20m\" folder, we access the `DataFrameReader` class through `read` and call the `csv()` method on it. We also specify `option(\"header\", \"true\")` since the first row of the file contains our column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      2|   3.5|1112486027|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|     32|   3.5|1112484819|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "|     1|     50|   3.5|1112484580|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.option(\"header\", \"true\").csv(\"ml-20m/ratings.csv\")\n",
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tuple of the `ratings` DataFrame represents one rating (`rating`) for one movie (`movieId`) by one user (`userId`). The ratings ranges from 0.5 stars (worst) up to 5.0 stars (best). \n",
    "\n",
    "We can also have look on the Schema of our dataset (column names and types) by using the `printSchema()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the `movies.csv` file. What kind of data is available and how does the schema look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = spark.read.option(\"header\", \"true\").csv(\"ml-20m/movies.csv\")\n",
    "movies.show(5)\n",
    "\n",
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro exercise 1: Which movies are the most popular ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the most popular movies, we are looking for the movies with the highest number of ratings. In this task, we assume the number of ratings as a representative for the number of views. To do this, we will perform the following *transformations* on the `ratings` DataFrame: \n",
    "- group by `movieId`\n",
    "- count the number of users (`userId`) associated with each movie \n",
    "- rename this column to `num_ratings`\n",
    "- sort by `num_ratings` in descending order \n",
    "\n",
    "We do these transformations in `pySpark` and store the DataFrame as `most_popular`. Have also a look on the [official pySpark documentation](https://spark.apache.org/docs/latest/api/python/pyspark.html).\n",
    "\n",
    "**HINT**:\n",
    "- Use `agg(count())` to perform an aggregate calculation on grouped data. \n",
    "- Don't forget that transformations are [lazy](https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-operations) in spark. We need to call an action (e.g. `show()`, `take()`) explicitly to see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|movieId|num_ratings|\n",
      "+-------+-----------+\n",
      "|    296|      67310|\n",
      "|    356|      66172|\n",
      "|    318|      63366|\n",
      "|    593|      63299|\n",
      "|    480|      59715|\n",
      "+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "most_popular = ratings.groupBy(\"movieId\").agg(count(\"userId\")).withColumnRenamed(\"count(userId)\", \"num_ratings\").sort(desc(\"num_ratings\"))\n",
    "\n",
    "most_popular.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the resulting table only contains `movieId` and `num_ratings`. The title of the movie is stored in the `movies` DataFrame. So, we need an inner join of our `most_popular` DataFrame with the `movies` DataFrame on `movieId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------+--------------------+--------------------+\n",
      "|movieId|num_ratings|movieId|               title|              genres|\n",
      "+-------+-----------+-------+--------------------+--------------------+\n",
      "|    296|      67310|    296| Pulp Fiction (1994)|Comedy|Crime|Dram...|\n",
      "|    356|      66172|    356| Forrest Gump (1994)|Comedy|Drama|Roma...|\n",
      "|    318|      63366|    318|Shawshank Redempt...|         Crime|Drama|\n",
      "|    593|      63299|    593|Silence of the La...|Crime|Horror|Thri...|\n",
      "|    480|      59715|    480|Jurassic Park (1993)|Action|Adventure|...|\n",
      "+-------+-----------+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_popular_movies = most_popular.join(movies, most_popular.movieId == movies.movieId)\n",
    "most_popular_movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of the most popular (or most rated) movies of our movielens dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro exercise 2: Understanding RDD's (Resilient Distributed Datasets)\n",
    "\n",
    "--> still ongoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['userId', 'movieId', 'rating', 'timestamp'],\n",
       " ['1', '2', '3.5', '1112486027'],\n",
       " ['1', '29', '3.5', '1112484676'],\n",
       " ['1', '32', '3.5', '1112484819'],\n",
       " ['1', '47', '3.5', '1112484727']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into RDD\n",
    "data = sc.textFile(\"ml-20m/ratings.csv\")\n",
    "\n",
    "# Split the RDD \n",
    "ratings = data.map(lambda l: l.split(','))\n",
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['timestamp', 'rating', 'movieId', 'userId'],\n",
       " ['1112486027', '3.5', '2', '1'],\n",
       " ['1112484676', '3.5', '29', '1'],\n",
       " ['1112484819', '3.5', '32', '1'],\n",
       " ['1112484727', '3.5', '47', '1']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map\n",
    "Reversed = ratings.map(lambda rating: rating[::-1])\n",
    "Reversed.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId',\n",
       " 'movieId',\n",
       " 'rating',\n",
       " 'timestamp',\n",
       " '1',\n",
       " '2',\n",
       " '3.5',\n",
       " '1112486027',\n",
       " '1',\n",
       " '29']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatMap\n",
    "characters = ratings.flatMap(lambda rating: list(rating))\n",
    "characters.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic exercise 1: Which movies have the highest ratings (in average)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see which movies are rated to be the best. We will use the `ratings` DataFrame and: \n",
    "\n",
    "- Group by `movieId` \n",
    "- Calculate the average rating for each movie and rename this column to `avg_rating`\n",
    "- Sort by `avg_rating` in descending order \n",
    "- Join the resulting DataFrame with the `movies` DataFrame to get the movienames.\n",
    "\n",
    "**NOTE** Be sure that you read the movies file in the first part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+--------------------+-------------+\n",
      "|movieId|avg_rating|movieId|               title|       genres|\n",
      "+-------+----------+-------+--------------------+-------------+\n",
      "|  95517|       5.0|  95517|Barchester Chroni...|        Drama|\n",
      "| 109715|       5.0| 109715|Inquire Within (2...|       Comedy|\n",
      "| 111548|       5.0| 111548|Welcome to Austra...|  Documentary|\n",
      "| 129905|       5.0| 129905|The Floating Cast...| Comedy|Drama|\n",
      "|  98761|       5.0|  98761|Shaolin Temple 2:...|Action|Comedy|\n",
      "+-------+----------+-------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_rated = ratings.groupBy(\"movieId\").agg(avg(col(\"rating\"))).withColumnRenamed(\"avg(rating)\", \"avg_rating\").sort(desc(\"avg_rating\"))\n",
    "\n",
    "top_rated_movies = top_rated.join(movies, top_rated.movieId == movies.movieId)\n",
    "\n",
    "top_rated_movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting Dataframe is maybe not meaningful. We should also consider the number of ratings by doing an aggregation `agg()` call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----------+-------+--------------------+-------------+\n",
      "|movieId|num_ratings|avg_rating|movieId|               title|       genres|\n",
      "+-------+-----------+----------+-------+--------------------+-------------+\n",
      "| 108527|          2|       5.0| 108527|  Catastroika (2012)|  Documentary|\n",
      "| 103871|          2|       5.0| 103871|Consuming Kids: T...|  Documentary|\n",
      "| 109715|          1|       5.0| 109715|Inquire Within (2...|       Comedy|\n",
      "|  98761|          1|       5.0|  98761|Shaolin Temple 2:...|Action|Comedy|\n",
      "| 129905|          1|       5.0| 129905|The Floating Cast...| Comedy|Drama|\n",
      "+-------+-----------+----------+-------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_rated = ratings.groupBy(\"movieId\").agg(count(\"userId\"), avg(col(\"rating\"))).withColumnRenamed(\"count(userId)\", \"num_ratings\").withColumnRenamed(\"avg(rating)\", \"avg_rating\")\n",
    "\n",
    "top_rated_movies = top_rated.join(movies, top_rated.movieId == movies.movieId).sort(desc(\"avg_rating\"), desc(\"num_ratings\"))\n",
    "\n",
    "top_rated_movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the movies with `avg_rating` of exactly 5.0 have 2 or less `num_ratings` . We must investigate the distribution of `num_ratings` to only consider movies that have a minimum number of ratings. Let's calculate some summary statistics within Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+\n",
      "| avg(num_ratings)|min(num_ratings)|max(num_ratings)|\n",
      "+-----------------+----------------+----------------+\n",
      "|747.8411232425965|               1|           67310|\n",
      "+-----------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate average, minimum, and maximum of num_ratings\n",
    "top_rated_movies.select([mean('num_ratings'), min('num_ratings'), max('num_ratings')]).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----------------+-------+--------------------+--------------------+\n",
      "|movieId|num_ratings|       avg_rating|movieId|               title|              genres|\n",
      "+-------+-----------+-----------------+-------+--------------------+--------------------+\n",
      "|    318|      63366|4.446990499637029|    318|Shawshank Redempt...|         Crime|Drama|\n",
      "|    858|      41355|4.364732196832306|    858|Godfather, The (1...|         Crime|Drama|\n",
      "|     50|      47006|4.334372207803259|     50|Usual Suspects, T...|Crime|Mystery|Thr...|\n",
      "|    527|      50054|4.310175010988133|    527|Schindler's List ...|           Drama|War|\n",
      "|   1221|      27398|4.275640557704942|   1221|Godfather: Part I...|         Crime|Drama|\n",
      "+-------+-----------+-----------------+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_rated_movies.where(\"num_ratings > 800\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing SparkSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "rdd = sc.textFile(\"ml-20m/ratings.csv\").map(lambda line: line.split(\",\").option(\"header\", \"true\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelinedRDD' object has no attribute 'createGlobalTempView'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-706914c45d1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateGlobalTempView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"movielens\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Global temporary view is tied to a system preserved database `global_temp`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM movielens\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PipelinedRDD' object has no attribute 'createGlobalTempView'"
     ]
    }
   ],
   "source": [
    "\n",
    "rdd.createGlobalTempView(\"movielens\")\n",
    "\n",
    "#Global temporary view is tied to a system preserved database `global_temp`\n",
    "spark.sql(\"SELECT * FROM movielens\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|   _c0|    _c1|   _c2|       _c3|\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "|     1|      2|   3.5|1112486027|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|     32|   3.5|1112484819|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RDDdata = spark.sql(\"SELECT * FROM csv.`ml-20m/ratings.csv`\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic exercise 2: Something with RDD's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced exercise 1: Which movies are a matter of taste?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, movies are a matter of taste. There are for sure some movies, which you would rate with a 5 whereas your friend rates the same movie with a 2. These are the movies that divide your opinon. Try to find out, which movies belong to this category.\n",
    "\n",
    "**HINT**\n",
    "\n",
    "- We need to consider the standard deviation of the movie ratings\n",
    "- Also, try to consider only movies that have some minimum number of ratings (e.g. 700) \n",
    "- Join with the movies table to get the movie names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------+------------------+\n",
      "|movieId|num_ratings|        avg_rating|        std_rating|\n",
      "+-------+-----------+------------------+------------------+\n",
      "|    296|      67310| 4.174231169217055|0.9760762295742448|\n",
      "|   1090|      15808| 3.919977226720648|0.8272067263021853|\n",
      "|   3959|       2869| 3.699372603694667|0.8607671626686736|\n",
      "|   2294|      10163| 3.303207714257601|0.9047000233824075|\n",
      "|   6731|       1173|3.5571184995737424| 0.918929235043451|\n",
      "+-------+-----------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_stddev = ratings.groupBy(\"movieId\").agg(count(\"userId\").alias(\"num_ratings\"), \n",
    "avg(col(\"rating\")).alias(\"avg_rating\"),stddev(col(\"rating\")).alias(\"std_rating\")).where(\"num_ratings > 700\")\n",
    "\n",
    "ratings_stddev.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------+------------------+-------+--------------------+--------------------+\n",
      "|movieId|num_ratings|        avg_rating|        std_rating|movieId|               title|              genres|\n",
      "+-------+-----------+------------------+------------------+-------+--------------------+--------------------+\n",
      "|   1924|       2304|2.6319444444444446| 1.420171182322382|   1924|Plan 9 from Outer...|       Horror|Sci-Fi|\n",
      "|   4255|       1550|2.1351612903225807|1.3504497277537106|   4255|Freddy Got Finger...|              Comedy|\n",
      "|  78772|        884| 2.670814479638009|1.3485057430514158|  78772|Twilight Saga: Ec...|Fantasy|Romance|T...|\n",
      "|  72407|       1135| 2.565638766519824|1.3367548401080391|  72407|Twilight Saga: Ne...|Drama|Fantasy|Hor...|\n",
      "|   7318|       3130| 3.185623003194888| 1.335427370705759|   7318|Passion of the Ch...|               Drama|\n",
      "+-------+-----------+------------------+------------------+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matterofTaste_movies = ratings_stddev.join(movies, ratings_stddev.movieId == movies.movieId)\n",
    "\n",
    "matterofTaste_movies.sort(desc(\"std_rating\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any surprise, Twilight is a highly debated movie ;) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "238px",
    "width": "412px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
